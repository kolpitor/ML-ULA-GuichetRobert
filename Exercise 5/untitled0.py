# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zeKArO782nqWm09Izz25fAYxzf6o6n62

Sélection du jeu de données :

Pour cette tâche, j'ai choisi le jeu de données "Supermarket Sales", qui est disponible sur Kaggle (https://www.kaggle.com/aungpyaeap/supermarket-sales). Cet ensemble de données contient des données sur les ventes d'une chaîne de supermarchés pour trois succursales différentes pendant trois mois.

L'ensemble de données comporte 1000 lignes et 17 colonnes, avec des colonnes telles que Succursale, Ville, Type de client, Sexe, Gamme de produits, Prix unitaire, Quantité, Taxe, Total, Date, Heure, Paiement et COGS (Coût des marchandises vendues).

L'objectif de cette tâche est d'effectuer un regroupement sur l'ensemble de données afin d'identifier différents segments de clientèle en fonction de leur comportement d'achat.

Approche:

Tout d'abord, je procéderai au nettoyage des données et à l'analyse exploratoire des données pour comprendre la distribution et les corrélations de l'ensemble de données. J'effectuerai ensuite l'ingénierie des fonctionnalités pour préparer

les données pour le regroupement. Enfin, j'effectuerai un clustering à l'aide de l'algorithme K-means et j'évaluerai les résultats.

Nettoyage des données et EDA :

Je vais commencer par importer les bibliothèques nécessaires et charger l'ensemble de données dans une base de données Pandas.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('supermarket_sales.csv')
print(data.head())

"""Le code ci-dessus affiche les cinq premières lignes de l'ensemble de données pour garantir que les données ont été chargées correctement.

Ensuite, je vérifie s'il y a des valeurs manquantes dans l'ensemble de données :
"""

print(data.isnull().sum())

"""Le code ci dessus affiche la somme des valeurs manquantes dans chaque colonne.

Après avoir vérifié les valeurs manquantes, je vérifierai la distribution des variables numériques dans l'ensemble de données en générant des histogrammes.
"""

num_cols = ['Unit price', 'Quantity', 'Tax 5%', 'Total', 'cogs']
for col in num_cols:
    plt.hist(data[col], bins=20)
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

"""Le code ci dessus génère des histogrammes pour les colonnes numériques de l'ensemble de données.

Ensuite, je vérifierai les corrélations entre les variables numériques dans l'ensemble de données.
"""

corr_matrix = data[num_cols].corr()
sns.heatmap(corr_matrix, annot=True)
plt.show()

"""Le code ci dessus génére une carte thermique de la matrice de corrélation entre les colonnes numériques de l'ensemble de données.

Ingénierie des fonctionnalités :

J'effectuerai l'ingénierie des fonctionnalités pour préparer les données au clustering.
"""

cat_cols = ['Branch', 'City', 'Customer type', 'Gender', 'Product line', 'Payment']

data_encoded = pd.get_dummies(data, columns=cat_cols)

num_cols_norm = ['Unit price', 'Quantity', 'Tax 5%', 'Total', 'cogs']
data_encoded[num_cols_norm] = (data_encoded[num_cols_norm] - data_encoded[num_cols_norm].mean()) / data_encoded[num_cols_norm].std()

print(data_encoded[['Unit price', 'Quantity', 'Tax 5%', 'Total', 'cogs']].head())

"""Cet extrait de code encodera à chaud les colonnes catégorielles dans l'ensemble de données et normalisera les colonnes numériques.

Clustering :

Je vais effectuer un clustering en utilisant l'algorithme K-means avec k=3 pour identifier différents segments de clientèle en fonction de leur comportement d'achat.
"""

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=3)
kmeans.fit(data_encoded[['Unit price', 'Quantity', 'Tax 5%', 'Total', 'cogs']])

cluster_labels = kmeans.predict(data_encoded[['Unit price', 'Quantity', 'Tax 5%', 'Total', 'cogs']])
data_encoded['cluster'] = cluster_labels

print(data_encoded[['Unit price', 'Quantity', 'Tax 5%', 'Total', 'cogs']].head())